{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-Intro-keras-tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXyOiFw0NrKx"
      },
      "source": [
        "Welcome to the Deep Learning Lab :)  \n",
        "Before starting this journey, here is a couple of ways to **load data into Colab** (in case you haven't done it before).  \n",
        "Colab can generate this scripts for you by clicking on the code icon (<>) on the left bar and selecting the code snippet you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cajMO4BPdCw"
      },
      "source": [
        "**Loading files from your local drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWwP_hNHNEvo"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gNyn1L3Pryh"
      },
      "source": [
        "You can access uploaded files via the folder icon on the left bar. You can also manipulate files by code, of course :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbsqXpYsP0P2"
      },
      "source": [
        "with open('plain_text_file.txt', 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKvrurkZNk3d"
      },
      "source": [
        "Or you can access directly your Google Drive!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0vckRqRNIOj"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8YwSbXZSFF2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_qWgbSrNdjn"
      },
      "source": [
        "\n",
        "# Introduction to Keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M0crmii8Ysb"
      },
      "source": [
        "Keras is a high-level, flexible library for deep learning experiments.  \n",
        "It is tightly integrated with Tensorflow, which provides low-level support.  \n",
        "\n",
        "**Warning:** Unless you are confident with what you are doing, in the beginning it is better if you stick with Keras as much as possible.  \n",
        "Use Tensorflow only when there is no alternative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAKZAX97Sox5"
      },
      "source": [
        "## Where do I start if I want to learn Keras?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZbgJpvUSvIA"
      },
      "source": [
        "Getting started *guide*: https://keras.io/getting_started/  \n",
        "You may want to choose *Introduction to Keras for Engineers*.\n",
        "\n",
        "Developer guide: https://keras.io/guides/  \n",
        "\n",
        "API documentation: https://keras.io/api/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Q3zv6RjiUt"
      },
      "source": [
        "from tensorflow import keras as K\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjdGEixplbmc"
      },
      "source": [
        "## Data manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY6DQMRuldzC"
      },
      "source": [
        "help(make_classification)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bna7Yrs6lgai"
      },
      "source": [
        "N_CLASSES = 3\n",
        "N_PATTERNS_PER_CLASS = 5000\n",
        "\n",
        "N_PATTERNS = N_CLASSES * N_PATTERNS_PER_CLASS\n",
        "X, y = make_classification(n_samples=N_PATTERNS, n_classes=N_CLASSES, n_informative=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCq1BhcSliBq"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bihyoidhljTS"
      },
      "source": [
        "X.dtype, y.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GThjCaclkkh"
      },
      "source": [
        "test_size = int(0.25 * y.shape[0])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB4SxhS4llyh"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26UpaZ7A9E3V"
      },
      "source": [
        "### Enter Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPik3nwM9yVh"
      },
      "source": [
        "Well, actually you can use numpy arrays directly in Keras, you don't have to do much...  \n",
        "You can also use Python generators\n",
        "\n",
        "But believe me, you will need something more advanced sooner or later.   \n",
        "Let's build a real Keras (actually, a Tensorflow) `Dataset` from those arrays!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alvksVvWk4vs"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7eC6khK-U5q"
      },
      "source": [
        "Ideally, you would like to use your dataset in a **training loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjkVS8NW-UPA"
      },
      "source": [
        "for x, y in dataset:\n",
        "    print(x.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFVyaTB-k8Vg"
      },
      "source": [
        "mmmm... no batch size?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDTbChrNlB5B"
      },
      "source": [
        "dataset = dataset.shuffle(buffer_size=1024).batch(32)\n",
        "for x, y in dataset:\n",
        "    print(x.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-8guWZClfT3"
      },
      "source": [
        "You can create a dataset from different sources (e.g. files in your hard disk).\n",
        "For example, try to build a dataset [from `csv` file](https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3d9xg3zVukr"
      },
      "source": [
        "**Exercise**: try to get acquainted with Tensorflow datasets. Try to build data from different sources (tensors, csv files, plain text file, folder structure...). Try to build datasets with one or more elements per iteration. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApYcbzaVllBl"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vDL3Rw9kLwz"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, Normalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUkJXGkTlt_t"
      },
      "source": [
        "Classes which take care of preprocessing your dataset. They can also contain a state (e.g. mean and std of your data). Updated with the `adapt` call (the `fit` method of scikit-learn).  \n",
        "**N.B.** the call to `adapt` changes the internal state of the normalizer, not the data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvx_7yyxkN9m"
      },
      "source": [
        "norm_layer = Normalization(axis=-1)\n",
        "norm_layer.adapt(X_train)\n",
        "norm_layer.mean, norm_layer.variance\n",
        "normalized_X_train = norm_layer(X_train)\n",
        "print(np.mean(normalized_X_train))\n",
        "print(np.var(normalized_X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSdPWHZbkORT"
      },
      "source": [
        "Rescaling and Normalization operates very similarly. However, `Rescaling` does not require the call to `adapt` since it has no internal state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-F9DfH9kbbo"
      },
      "source": [
        "help(Rescaling)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkNSY14UeKdY"
      },
      "source": [
        "## Functional API "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ-dPbH6b_jA"
      },
      "source": [
        "This is one of the powerful features of Keras. **Easily build complex models!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-3hQy1bIwnV"
      },
      "source": [
        "A model is composed by **layers**.\n",
        "\n",
        "A layer takes an input and returns an output (usually by using adaptive parameters).  \n",
        "A model is built by composing many layers and it also exposes a more complex interface with methods for training, inference etc..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9RpgoiIjvD3"
      },
      "source": [
        "model = K.Sequential()\n",
        "model.add(K.layers.Dense(units=64, activation='relu'))\n",
        "model.add(K.layers.Dense(units=N_CLASSES, activation='softmax'))\n",
        "#model.summary() # will fail! what is the input of this model?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVJkx9NSiPsp"
      },
      "source": [
        "Keras does not require you to specify the `Input` of a model.  \n",
        "Instead, it tries to dynamically infer the model input layer when yuo call it with data. However, you can always specify it explicitly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_T5fJ3Bj4cI"
      },
      "source": [
        "We need **sparse_categorical_crossentropy** because we are *not* dealing with one-hot targets but with numerical targets.  \n",
        "You can use **categorical_crossentropy** if the targets are one-hot encoded.  \n",
        "Keras can convert to one-hot: `K.utils.to_categorical`.  \n",
        "[You can also use scikit-learn to encode your targets in one-hot form](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN9JZ_kK_gxG"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rnyLzHzCHvc"
      },
      "source": [
        "Keras metrics description: https://keras.io/api/metrics/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy-tAQe5j6ub"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrEv7A1KFSxq"
      },
      "source": [
        "You can also pass a Keras dataset to the fit. Try it out!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytVH3A02j1RS"
      },
      "source": [
        "Since I did not specify the `Input` what will happen if I change the input size?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H53SeDfyjtVM"
      },
      "source": [
        "# model.fit(X_train[:, :3], y_train, epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BzeUeXjXRVs"
      },
      "source": [
        "What's happening under-the-hood of `fit`?  \n",
        "Basically, loop over training set, compute model predictions, compute loss, compute gradients, update model parameters (and much more). We will see how to implement a basic fit from scratch later on. We will need Tensorflow for that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdJgSv_j_1d"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "*Keras* returns loss and all the metrics you previously specified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQI1Wj3PkChT"
      },
      "source": [
        "metrics = model.evaluate(X_test, y_test)\n",
        "metrics # loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hafchirDkEeO"
      },
      "source": [
        "predictions = model.predict(X_test[:20])\n",
        "print(predictions.shape)\n",
        "predictions.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLXbAOF1TWu3"
      },
      "source": [
        "You can use metrics also standalone by instantiating them, calling `update_states`, `reset_states` and `result`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxk-4jYSyaCP"
      },
      "source": [
        "### Save your model and load it again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBMcK8_nIf5F"
      },
      "source": [
        "Fundamental to manage long training processes and to use your trained model for inference.\n",
        "\n",
        "`Model serialization` helps also when training on colab (runtime can disconnect after a while)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEdOYZpCycm2"
      },
      "source": [
        "# save weights, optimizer state, model topology\n",
        "model.save('my_model.h5') # common file format to save models\n",
        "del model\n",
        "# if it was already compiled, it will be compiled and viceversa\n",
        "loaded_model = K.models.load_model('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlP-jZzBzQcg"
      },
      "source": [
        "Alternatively, you can only save and load the weights. Try the `save_weights` and `load_weights`.  \n",
        "Model saving guide: https://keras.io/guides/serialization_and_saving/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFBmfRvdBnhC"
      },
      "source": [
        "### Functional API v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgydqfheoYEY"
      },
      "source": [
        "***Alternative (but similar) way to use the functional API*** *italicized text*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg3PXb6Gkgls"
      },
      "source": [
        "None is used in a tensor size when you don't know the size. In the functional API, `batch size` is assumed to be None and added by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_hnAUPIkle5"
      },
      "source": [
        "# input layer\n",
        "inputs = K.Input(shape=(20,)) # here the size is (None, 20)\n",
        "x = norm_layer(inputs)\n",
        "x = K.layers.Dense(units=64, activation='relu')(x)\n",
        "outputs = K.layers.Dense(units=N_CLASSES, activation='softmax')(x)\n",
        "model = K.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCKH2ETCkr-h"
      },
      "source": [
        "model.compile(optimizer=K.optimizers.SGD(learning_rate=1e-2), loss=K.losses.SparseCategoricalCrossentropy())\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-OBjiY3kvtO"
      },
      "source": [
        "metrics = model.evaluate(X_test, y_test)\n",
        "metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A49Yk3-HlMxW"
      },
      "source": [
        "## Use validation dataset and plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqnheziAlQpU"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n",
        "                                        test_size=int(0.25*y_train.shape[0]), shuffle=True, stratify=y_train)\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg1d3vqKlSwx"
      },
      "source": [
        "we should recompute the `Normalization`, because statistics are computed also on what now is the validation dataset! Anyway..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvkygNj8lUUf"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_valid, y_valid))\n",
        "vars(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f41nHr18AMFO"
      },
      "source": [
        "help(K.Model.fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPTgioTeAzl2"
      },
      "source": [
        "help(K.callbacks.History)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8YnPSOgBN8v"
      },
      "source": [
        "Mmm... callbacks? Seems interesting!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p6OR93ZlXs1"
      },
      "source": [
        "plt.plot(history.history['loss'], 'b-', label='train_loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='validation_loss')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6XNdfNHWPUh"
      },
      "source": [
        "**Exercise**: at this point you have more or less all you need to perform basic DL experiments. Try to train your first model on a Keras dataset and see what happens. Do not focus on performance, but rather on setting up your code to be reused later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ADgV_bYd8Lx"
      },
      "source": [
        "## Checkpointing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eB69CwpCXH3"
      },
      "source": [
        "Callbacks are functions that are called at particular moments in time automatically. You can pass callbacks to the `fit` function.\n",
        "https://keras.io/api/callbacks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCMx9g1sCdya"
      },
      "source": [
        "help(K.callbacks.ModelCheckpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHcRtKULCpCn"
      },
      "source": [
        "callback_list = [K.callbacks.ModelCheckpoint(\n",
        "                    filepath='model_{epoch}',\n",
        "                    save_freq='epoch')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0WxUCl7lDTp"
      },
      "source": [
        "history = model.fit(dataset, epochs=10, callbacks=callback_list)\n",
        "metrics = model.evaluate(X_test, y_test)\n",
        "print(metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYMrt8H6ULpW"
      },
      "source": [
        "## Eager execution vs. compiled execution!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ZKNOS2Dkcq"
      },
      "source": [
        "Compiled means that each line of code adds a component to the **computational graph**, it does not execute what the line states.  \n",
        "After PyTorch came in, the advantages of eager execution became evident, especially when it comes to rapid prototyping and debugging. In eager execution, each line of code is immediately executed and the results returned to the user (imperative programming interface). You can use `print` and debugger to see results of your operations.  \n",
        "For deployment in real world applications, compiled is far more efficient (PyTorch now provides support also for this version).\n",
        "\n",
        "Keras run the model in compiled version by default, TF now uses eager by default. That means you cannot debug it line by line or through prints. To enable eager execution, set `run_eagerly=True` in `compile` call.  \n",
        "In TF you can use a TF Function to pass to compiled graph: https://www.tensorflow.org/guide/function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwYpqBPZjDHI"
      },
      "source": [
        "## GPU or CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlRj-u1djG8b"
      },
      "source": [
        "TF and Keras automatically use GPU, when available.\n",
        "You can specify where to send each tensor explicitly, if you prefer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN3m-qILjW3_"
      },
      "source": [
        "import tensorflow as tf\n",
        "with tf.device('/CPU:0'):\n",
        "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUDJxAPMjfmv"
      },
      "source": [
        "a.device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f083MOMQjhb_"
      },
      "source": [
        "Check out if there is a GPU available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KleYAsstjjjq"
      },
      "source": [
        "len(tf.config.list_physical_devices('GPU'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZlBexngju_W"
      },
      "source": [
        "b = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b.device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmxEug2P1uQb"
      },
      "source": [
        "# Low Level API - Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cmD5mfu17IO"
      },
      "source": [
        "Tensorflow is the \"backend\" of Keras: https://www.tensorflow.org/overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "418AyDyzPbEb"
      },
      "source": [
        "print(tf.executing_eagerly())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BveBnUdWwIW"
      },
      "source": [
        "x = tf.constant([1,2,3,4,5,6], dtype=tf.float32)\n",
        "print(x, x.shape)\n",
        "print(x.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeVdnnXUssrn"
      },
      "source": [
        "print(tf.cast(x, tf.float64))\n",
        "print(tf.cast(x, tf.int32))\n",
        "#print(tf.cast(x, tf.string)) # error!\n",
        "print(tf.strings.as_string(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lhQ2kYcthJ5"
      },
      "source": [
        "for el in x:\n",
        "  print(el)\n",
        "  print(float(el))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLT494xTsCgV"
      },
      "source": [
        "new_x = tf.reshape(x, [2,3])\n",
        "print(new_x, new_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N13SRyzesLst"
      },
      "source": [
        "# indexing\n",
        "print(new_x[:, 0])\n",
        "print(new_x[:, :])\n",
        "print(new_x[0, 2])\n",
        "print(new_x[-1, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi7nYNdQseyK"
      },
      "source": [
        "tf.transpose(new_x, [1, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73lmqJ5hWyBF"
      },
      "source": [
        "tf.random.uniform(minval=0, maxval=1, shape=(3,4), dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBV_5XvFSBTM"
      },
      "source": [
        "Check out also `tf.zeros`, `tf.ones`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCdgMNILW_U0"
      },
      "source": [
        "A `Variable` is a tensor with a state you can update"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys3oFHHQWzci"
      },
      "source": [
        "w = tf.Variable(x) # set x as initial value for w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGAovzk_W6fq"
      },
      "source": [
        "print(w.assign(x + 1)) # + operator does broadcast\n",
        "print(w.assign_add(x))\n",
        "# print(w.assign_add(1)) # assign_add does not broadcast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmkkJMfxXD0Q"
      },
      "source": [
        "## Compute Gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55kjb6svXHR7"
      },
      "source": [
        "print(w)\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(w)\n",
        "    w_squared =  tf.square(w)\n",
        "    grad = tape.gradient(w_squared, w)\n",
        "print(grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9rRuSwNXKaM"
      },
      "source": [
        "does `w` need to be a `Variable`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S_b4fNwXNW-"
      },
      "source": [
        "print(x)\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(x) # what happens if you remove this line?\n",
        "    x_squared =  tf.square(x)\n",
        "    grad = tape.gradient(x_squared, x)\n",
        "print(grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5KRQ17IXQ9j"
      },
      "source": [
        "`Variable` is watched automatically (tensorflow supposes that you will be interested in that gradient)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfCVVYNUXPCl"
      },
      "source": [
        "print(w)\n",
        "with tf.GradientTape() as tape:\n",
        "    w_squared =  tf.square(w)\n",
        "    grad = tape.gradient(w_squared, w)\n",
        "print(grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TP6IniIXUra"
      },
      "source": [
        "Second-order derivatives??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYXH3gUHXYE_"
      },
      "source": [
        "# second derivatives\n",
        "print(w)\n",
        "with tf.GradientTape() as tape:\n",
        "    with tf.GradientTape() as tape_inner:\n",
        "        w_squared =  tf.square(w)\n",
        "        grad = tape_inner.gradient(w_squared, w)\n",
        "    print(grad)\n",
        "    grad2 = tape.gradient(grad, w)\n",
        "print(grad2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1NfMwNUSp7r"
      },
      "source": [
        "### From eager to compiled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cFv2sYXSukN"
      },
      "source": [
        "@tf.function  # python decorator\n",
        "def compiled_function(x):\n",
        "  y = x * 3\n",
        "  print(\"Compiled tensor: \", y)\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCFa7eeaS77R"
      },
      "source": [
        "out = compiled_function(tf.Variable(tf.ones([2, 5], tf.int32)))\n",
        "print(\"Eager result: \", out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKGoTyygT5Qp"
      },
      "source": [
        "The compilation prevents the tensor in the compiled function to be printed.  \n",
        "What is actually printed is the name of the node in the computational graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiE9lMU9UFkg"
      },
      "source": [
        "# Combining Keras and TF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hJBUUg9UHmL"
      },
      "source": [
        "Despite being a high-level library for DL, Keras offers you the possibility to customize different parts of your DL pipeline.  \n",
        "Especially if you are willing to deal with TF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F90d4p37ofQv"
      },
      "source": [
        "class CustomDense(K.layers.Layer):\n",
        "    def __init__(self, input_dim, units=64):\n",
        "        super(CustomDense, self).__init__() # this call is needed to set up the Layer\n",
        "\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
        "            trainable=True) # this means that w will be updated\n",
        "\n",
        "        b_init = tf.zeros_initializer()\n",
        "        self.b = tf.Variable(\n",
        "            initial_value=b_init(shape=(units,), dtype=\"float32\"), \n",
        "            trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        This method is automatically called when you call an instance of Linear\n",
        "        e.g. out = linear(x)\n",
        "        \"\"\"\n",
        "        preact = tf.matmul(inputs, self.w) + self.b\n",
        "        postact = tf.nn.relu(preact)\n",
        "        return postact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNOOrjaa-1dU"
      },
      "source": [
        "or equivalently"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2eA-IOu-2kD"
      },
      "source": [
        "class CustomDense2(K.layers.Layer):\n",
        "\n",
        "    def __init__(self, units=64):\n",
        "      super(CustomDense2, self).__init__()\n",
        "      self.units = units\n",
        "      # we are not specifying input size here...\n",
        "      # ring a bell?\n",
        "\n",
        "    def build(self, input_shape):\n",
        "      \"\"\"\n",
        "      Lazily called when an input is provided to the model\n",
        "      \"\"\"\n",
        "      self.w = self.add_weight(\n",
        "        shape=(input_shape[-1], self.units),\n",
        "        initializer=\"random_normal\",\n",
        "        trainable=True)\n",
        "        \n",
        "      self.b = self.add_weight(\n",
        "        shape=(self.units,), initializer=\"random_normal\", trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "      preact = tf.matmul(inputs, self.w) + self.b\n",
        "      postact = tf.nn.relu(preact)\n",
        "      return postact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZTVzL1gowHM"
      },
      "source": [
        "**Many** Keras predefined `Layers`: https://keras.io/api/layers/  \n",
        "**Many** TF activation functions: https://www.tensorflow.org/api_docs/python/tf/nn/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emtgBKelrHXR"
      },
      "source": [
        "l = CustomDense(4)\n",
        "x = tf.linspace(0, 20, 20)\n",
        "out = l(tf.reshape(x, [5,4]))\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX_k0Wlk-n2K"
      },
      "source": [
        "l.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEnU2d3XZVfx"
      },
      "source": [
        "Ok... now what?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzRT77Z_ZUf3"
      },
      "source": [
        "# Instantiate an optimizer.\n",
        "optimizer = K.optimizers.SGD(learning_rate=1e-3)\n",
        "criterion = K.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model = CustomDense2()\n",
        "for step, (x, y) in enumerate(dataset):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        logits = model(x)\n",
        "        loss = criterion(y, logits)\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    # you can modify gradients before updating the model\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVOCq5N7Z_65"
      },
      "source": [
        "A `weight` with `training=False` will not appear in `trainable_weights` iterator. There is a specific `non_trainable_weights`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hAhhzeKaW6l"
      },
      "source": [
        "**Exercise**: build a custom Multi Layer Perceptron (i.e. a feedforward neural network) by leveraging the modules we already created. Try and experiment with this model by training it on a dataset (either a Keras one or a fake one)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bcoi60iCqNi"
      },
      "source": [
        "**Exercise**: try out an Autoencoder. Encoder and Decoder are both feedforward networks. Try to encode patterns of a dataset, decode them and see how much reconstruction error you got! "
      ]
    }
  ]
}