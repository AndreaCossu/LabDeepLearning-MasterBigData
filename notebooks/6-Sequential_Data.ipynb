{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-Sequential Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aouKTcMK8OI0"
      },
      "source": [
        "# Sequences, sequences everywhere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hndpu8WsaoX"
      },
      "source": [
        "Sequence may come from different applications: sentences, audio, video, sensors...  \n",
        "All of them presents feature vectors associated to a growing \"time step\" index.  \n",
        "\n",
        "Each pattern in the sequence is not i.i.d. with the other patterns in the same sequence. We usually assume i.i.d. between different sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd93TiF4vslb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj0vqlzrvKqt"
      },
      "source": [
        "## Sequences with feedforward networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04zAMqqKvM6v"
      },
      "source": [
        "Why can't we use the usual MLP and live happy?  \n",
        "Well, it turns out that, sometimes, you can! \n",
        "\n",
        "Let's take **sequence classification** as an example (Q: which are other possible tasks in sequence learning?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RLu8iCuy67v"
      },
      "source": [
        "Btw: I prefer to work with `batch_first` tensor layout but feel free to use what it seems best for your case. Usually, you just need to select the appropriate layout in the RNN models (see next)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD721sk3vKAb"
      },
      "source": [
        "batch_size, sequence_length, input_size =  10, 7, 3\n",
        "num_classes = 2\n",
        "x = tf.random.uniform(minval=-2, maxval=2, shape=(batch_size, sequence_length, input_size), dtype=tf.float32)\n",
        "y = tf.random.uniform(minval=0, maxval=num_classes, shape=(batch_size,), dtype=tf.int32)\n",
        "# plot first sequence, first feature\n",
        "plt.plot(np.arange(0, sequence_length), x[0, :, 0]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wiqmI2NxSLP"
      },
      "source": [
        "Let's build a MLP which produces a linear projections **for each element** in the sequence. Each feature point of each time step has its own parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wR6-h3MwCKJ"
      },
      "source": [
        "model = K.Sequential()\n",
        "model.add(K.layers.Input(shape=(sequence_length, input_size)))\n",
        "model.add(K.layers.Reshape((sequence_length*input_size,)))\n",
        "model.add(K.layers.Dense(32, activation=\"tanh\"))\n",
        "model.add(K.layers.Dense(num_classes, activation=\"softmax\"))\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "model.fit(x, y, epochs=2, batch_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0isbp7pyQE3"
      },
      "source": [
        "We treated each feature point as i.i.d. with the others -> we lost time dependency! We are back to tabular data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjlSp_KzyZXE"
      },
      "source": [
        "What if we use a **RNN** instead?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrDy1_yiyYwV"
      },
      "source": [
        "model = K.Sequential()\n",
        "model.add(K.layers.Input(shape=(sequence_length, input_size)))\n",
        "model.add(K.layers.SimpleRNN(32, time_major=False)) # this is the default, turn it to True to disable `batch_first`\n",
        "model.add(K.layers.Dense(num_classes, activation=\"softmax\"))\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "model.fit(x, y, epochs=2, batch_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-O_-UF54MkK"
      },
      "source": [
        "## Inspecting RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAdjvZ1p4PkC"
      },
      "source": [
        "layer = K.layers.SimpleRNN(32)\n",
        "out = layer(x)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Ma2W6N4cqY"
      },
      "source": [
        "Ok, we \"lost\" time dimension so we can use this output directly to perform sequence classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6ty6uS64i10"
      },
      "source": [
        "What if I want the output of the RNN at each time step?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSFmuwJa4m6T"
      },
      "source": [
        "layer = K.layers.SimpleRNN(32, return_sequences=True)\n",
        "out = layer(x)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByPgSg62412I"
      },
      "source": [
        "Great! What more?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL3V7TrF43q5"
      },
      "source": [
        "# return last state\n",
        "layer = K.layers.SimpleRNN(32, return_state=True)\n",
        "out, h = layer(x)\n",
        "print(out.shape, h.shape)\n",
        "print(tf.math.reduce_all(out == h))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwYN0xmy5Qc7"
      },
      "source": [
        "Ok, so the output it is equal to the state!\n",
        "\n",
        "But if they are equal, why two different options? Well... RNN state can be a quite complicated object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czwUY9By5WFQ"
      },
      "source": [
        "layer = K.layers.LSTM(32, return_state=True)\n",
        "out, h, c = layer(x)\n",
        "print(out.shape, h.shape, c.shape)\n",
        "print(tf.math.reduce_all(out == h))\n",
        "print(tf.math.reduce_all(out == c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7uAy4kU53yn"
      },
      "source": [
        "If you don't want the state, you won't notice the difference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CrKSmvE50ar"
      },
      "source": [
        "layer = K.layers.LSTM(32, return_sequences=True)\n",
        "out = layer(x)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBolwTTu0UJ-"
      },
      "source": [
        "### RNN cells vs. RNN layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkSTf1fT01zb"
      },
      "source": [
        "**Checkout [this Keras guide on working with RNNs](https://keras.io/guides/working_with_rnns/).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCdu4f7M0Ye1"
      },
      "source": [
        "How RNNs are implemented? Basically, each RNN processes batches of sequences. \n",
        "\n",
        "The RNN is internally built by a fixed number of RNN cells. Each cell process one timestep only (a single feature vector),. Its output is \"forwarded\" back to its input to create time dependency. It also keep an internal state which is updated each time it receives a vector.\n",
        "\n",
        "The RNN use RNN cells into the loop over time steps.\n",
        "\n",
        "* **The cell state size determines the ouput size of the RNN: `output_size * num_cells`**\n",
        "* **If you use more than one cell, you get a `stacked` RNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chGdGW5i_5U5"
      },
      "source": [
        "## Deep RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDFOoqXXCd36"
      },
      "source": [
        "Let's go deep and add more layers! It's so easy, there is little I can tell you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huVHOx2l_7Kh"
      },
      "source": [
        "model = K.Sequential()\n",
        "model.add(K.layers.GRU(32, return_sequences=True)) # you need a 3D output\n",
        "model.add(K.layers.GRU(64))\n",
        "model.add(K.layers.Dense(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFZRKGsZ89I4"
      },
      "source": [
        "## Apply the same layer multiple times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wridJaZ59AhH"
      },
      "source": [
        "You can easily apply weight sharing on any layer you have by using `TimeDistributed` Layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fa9QHLg3g8O"
      },
      "source": [
        "inputs = K.Input(shape=(sequence_length, input_size))\n",
        "layer = K.layers.Dense(32)\n",
        "outputs = K.layers.TimeDistributed(layer)(inputs) # replicate the layer over the second dimension\n",
        "outputs.shape \n",
        "# do whatever you want with `outputs` depending on the task"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRDGd0aX-QOl"
      },
      "source": [
        "## Use Convolutions to deal with sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VGBPbhG-WZz"
      },
      "source": [
        "Convolutions are heavily used also on 1D patterns like sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb8sz3Fw--gT"
      },
      "source": [
        "inputs = K.layers.Input((sequence_length, input_size))\n",
        "conv1 = K.layers.Conv1D(filters=32, kernel_size=2, padding=\"same\")(inputs)\n",
        "conv1 = K.layers.ReLU()(conv1)\n",
        "\n",
        "conv2 = K.layers.Conv1D(filters=64, kernel_size=2, padding=\"same\")(conv1)\n",
        "conv2 = K.layers.ReLU()(conv2)\n",
        "\n",
        "final = K.layers.GlobalAveragePooling1D()(conv2)\n",
        "outputs = K.layers.Dense(num_classes, activation=\"softmax\")(final)\n",
        "\n",
        "model = K.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "model.fit(x, y, epochs=2, batch_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBzX-dkwAedT"
      },
      "source": [
        "## Sequences of different lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RepbB-DxAhBf"
      },
      "source": [
        "batch_size, max_sequence_length, input_size =  10, 7, 3\n",
        "num_classes = 2\n",
        "\n",
        "x1 = tf.random.uniform(minval=-2, maxval=2, shape=(int(batch_size/2), sequence_length, input_size), dtype=tf.float32)\n",
        "x2 = tf.random.uniform(minval=-2, maxval=2, shape=(int(batch_size/2), max_sequence_length-3, input_size), dtype=tf.float32)\n",
        "\n",
        "y = tf.random.uniform(minval=0, maxval=num_classes, shape=(batch_size,), dtype=tf.int32)\n",
        "# plot first sequence, first feature\n",
        "fig, ax = plt.subplots(2)\n",
        "ax[0].plot(np.arange(0, x1.shape[1]), x1[0, :, 0]) \n",
        "ax[1].plot(np.arange(0, x2.shape[1]), x2[0, :, 0]) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHqs9LjsB4n3"
      },
      "source": [
        "How can we build a dataset or simply a single numpy array for `x`?\n",
        "\n",
        "**Padding**!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36p5WcjRB-ho"
      },
      "source": [
        "padded = K.preprocessing.sequence.pad_sequences(list(x1) + list(x2), \n",
        "                                                padding=\"post\", value=0, # post is required to work with cuda\n",
        "                                                dtype=\"float32\") \n",
        "\n",
        "print(padded.shape)\n",
        "print(padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2jWGXWgDgNz"
      },
      "source": [
        "Padding adds 0 values. You can also pad to a fixed length and truncate longer sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGS_UyT-DpBq"
      },
      "source": [
        "This is now a dataset like the first one we built and can be fed to all the previous models. \n",
        "\n",
        "However, you do not usually want to compute loss and backpropagation for all the padded time steps. You should compute them only for the \"real\" time steps.\n",
        "\n",
        "**Masking**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShCRhnZmE9Kx"
      },
      "source": [
        "A boolean tensor with shape `batch_size, sequence length` which is False whenever that time step has to be skipped, True otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aabjBUDVFG74"
      },
      "source": [
        "Some layers (e.g. RNN) accepts a mask parameter together with input during forward. \n",
        "\n",
        "You can always use the `Masking` layer directly.  \n",
        "Masks propagate in the model. If a previous layer uses masks and the current layer accepts masks, it will receive them automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3itbvAAxD5fd"
      },
      "source": [
        "lstm = K.layers.LSTM(32, return_sequences=True)\n",
        "mask = tf.sequence_mask([sequence_length]*int(batch_size/2)+[sequence_length-3]*int(batch_size/2), \n",
        "                        maxlen=sequence_length)\n",
        "print(mask.shape)\n",
        "print(mask)\n",
        "out = lstm(padded, mask=mask)\n",
        "print(out.shape)\n",
        "# only the non-masked positions will be taken into consideration whenfor computing gradients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWI_feZbEiJq"
      },
      "source": [
        "or also"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BQ8WDXLEi7N"
      },
      "source": [
        "# this layer will ignore every pattern containing all zeros\n",
        "# you can use it in your models as an usual layer\n",
        "mask_layer = K.layers.Masking(mask_value=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGu_GwttClkg"
      },
      "source": [
        "## Sliding windows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjgn6AhUCqXv"
      },
      "source": [
        "help(K.preprocessing.timeseries_dataset_from_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUdCgv6zBNUU"
      },
      "source": [
        "**Exercise**: build a model of your choice to classify sequences. You can try also with MNIST if you feel comfortable. Try to use 1 or 28 pixels at a time to create the sequence.\n",
        "\n",
        "Otherwise, you can look for specific datasets online in the usual UCI (ask me for advices :) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbrG6WymBKvd"
      },
      "source": [
        "## Beyond classification: sequence modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CaalL5KGayN"
      },
      "source": [
        "Example: https://keras.io/examples/timeseries/timeseries_anomaly_detection/\n",
        "\n",
        "Notebook: https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_weather_forecasting.ipynb#scrollTo=Arln3kkJDQtq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIV7um_tGrXZ"
      },
      "source": [
        "## Natural Language Processing: sequences of tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yyGP2tnqwN8"
      },
      "source": [
        "How to manage sentences? Well they are a sequences of words, right?\n",
        "\n",
        "Lots of preprocessing and then -> DL model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIBpKfhjq5HX"
      },
      "source": [
        "sentence = [\"Hi, how are you\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y8MWqz1rBFw"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjyCX8YqtwAC"
      },
      "source": [
        "**Each word becomes an integer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7XssnVRrITx"
      },
      "source": [
        "vect = TextVectorization(max_tokens=20,\n",
        "                         ngrams=None,\n",
        "                         output_mode=\"int\", \n",
        "                         output_sequence_length=20, \n",
        "                         pad_to_max_tokens=False, \n",
        "                         vocabulary=None)\n",
        "vect.adapt(sentence)\n",
        "print(vect.get_vocabulary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx5e1uWOs3rA"
      },
      "source": [
        "out = vect(sentence)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPPGlzFvylFi"
      },
      "source": [
        "**You may want also ngrams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAI4AtpSyrT4"
      },
      "source": [
        "vect = TextVectorization(max_tokens=20,\n",
        "                         ngrams=2,\n",
        "                         output_mode=\"int\", \n",
        "                         output_sequence_length=20, \n",
        "                         pad_to_max_tokens=False, \n",
        "                         vocabulary=None)\n",
        "vect.adapt(sentence)\n",
        "print(vect.get_vocabulary())\n",
        "out = vect(sentence)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4mqMg8NzDj2"
      },
      "source": [
        "output changed to include also found ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGw6AyOVzqYJ"
      },
      "source": [
        "**How to feed these results to a DL model?**\n",
        "\n",
        "You *cannot* feed integers! 0 > 1 > 2 > 3  *does not compare with* you > how are > how\n",
        "\n",
        "* Feed one-hot encodings\n",
        "* Feed embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKbB_gy89yAp"
      },
      "source": [
        "**One-hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmV8VGVX0ABc"
      },
      "source": [
        "vect = TextVectorization(max_tokens=20,\n",
        "                         output_mode=\"int\", \n",
        "                         output_sequence_length=10)\n",
        "vect.adapt(sentence)\n",
        "print(vect.get_vocabulary())\n",
        "\n",
        "# one hot encoding\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "to_encode = vect(sentence)\n",
        "print(to_encode)\n",
        "encoded = to_categorical(to_encode, num_classes=len(vect.get_vocabulary()))\n",
        "print(encoded)\n",
        "print(encoded.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxelVMc50oyH"
      },
      "source": [
        "You just need to take sentences in batches and you are fine!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbB9fsmN94Yz"
      },
      "source": [
        "**The most used version in NLP is Embedding**\n",
        "\n",
        "Let's create a dataset of words!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj-BdbTR0tXi"
      },
      "source": [
        "#just another way to break into words\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "print(text_to_word_sequence(sentence[0]))\n",
        "print()\n",
        "\n",
        "features = [[\"hello it me\"], \n",
        "            [\"how to escape\"],\n",
        "            [\"beware of dog\"]]\n",
        "labels = tf.random.uniform(minval=0, maxval=2, shape=(len(features),), dtype=tf.int32)\n",
        "text_only_dataset = tf.data.Dataset.from_tensor_slices(features) # this is used only to adapt the vectorization\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "dataset = dataset.shuffle(buffer_size=100).batch(2)\n",
        "for x, y in dataset:\n",
        "  print(x, y)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yytp_F2x572K"
      },
      "source": [
        "vect = TextVectorization(max_tokens=20,\n",
        "                         ngrams=None,\n",
        "                         output_mode=\"int\", \n",
        "                         output_sequence_length=20, \n",
        "                         pad_to_max_tokens=False, \n",
        "                         vocabulary=None)\n",
        "vect.adapt(text_only_dataset)\n",
        "print(vect.get_vocabulary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp5pslRh9XxU"
      },
      "source": [
        "embedding = K.layers.Embedding(input_dim=len(vect.get_vocabulary()),\n",
        "                               output_dim=10)\n",
        "print(embedding(vect(features)).shape)\n",
        "print(embedding(vect(features)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxLeCLPB4jIU"
      },
      "source": [
        "Now, build a model! Strings are a valid tensor type so we are fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtfdk4_x4ipG"
      },
      "source": [
        "model = K.Sequential()\n",
        "# is a tensor of size (batch_size, 1) because each element\n",
        "# is a single sentence (like \"hello it me\" -> size = 1)\n",
        "model.add(K.layers.Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vect)\n",
        "model.add(embedding) # 3D output\n",
        "model.add(K.layers.LSTM(32)) # one word at a time\n",
        "model.add(K.layers.Dense(2, activation=\"softmax\"))\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(dataset, epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMkgw6PqE7aI"
      },
      "source": [
        "**Bonus**: NLP often uses Bidirectional RNNs -> process sequence in reverse. \n",
        "You can use the `Bidirectional` keras layer or the `go_backward` parameter in RNN constructor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMBGpEOe_TTl"
      },
      "source": [
        "**You now have all the basics to deal with NLP tasks, too**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3MTU43tGWM-"
      },
      "source": [
        "You can also try out the `Attention` and `Transformer` architecture. These are popular models for NLP. However they are usually very large (dense), with lots of parameters and they require lots of training time.\n",
        "\n",
        "You can use Colab but you have to periodically checkpointing your model so that when (not if) the runtime gets disconnected you don't lose everything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsONAt3AG-V8"
      },
      "source": [
        "[Multi-head attention](https://keras.io/api/layers/attention_layers/multi_head_attention/)\n",
        "\n",
        "\n",
        "[Transformer Example](https://keras.io/examples/nlp/text_classification_with_transformer/#implement-a-transformer-block-as-a-layer)"
      ]
    }
  ]
}