{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-Computer Vision.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BS-dcBEYtr5"
      },
      "source": [
        "# Compute Vision: the Deep Learning breakthrough"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOI3u_TnZmap"
      },
      "source": [
        "Around 2012, Deep Convolutional Neural Networks broke all the records in Computer Vision competitions. This paved the wave to the Deep Learning *era*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA2YwtTUZ4e-"
      },
      "source": [
        "Let's start from the basics! We will load a dataset of images.\n",
        "\n",
        "The [`CIFAR-10`](https://www.cs.toronto.edu/~kriz/cifar.html) dataset! Btw, if you are doing deep learning you **have** to know [MNIST dataset](https://keras.io/api/datasets/mnist/).  \n",
        "However, since I overfit on that, we will work we the not-less-famous CIFAR :) \n",
        "\n",
        "\n",
        "Note: you can use [`load_img`](https://keras.io/api/preprocessing/image/#loadimg-function) and [`img_to_array`](https://keras.io/api/preprocessing/image/#imgtoarray-function) to load images from file (into PIL images) and to convert them into numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29f27RUXafyd"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras as K\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRmdVfKwa1Fd"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyGJ45FzbILO"
      },
      "source": [
        "Let's see what we have got!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s5fkJoXbFHR"
      },
      "source": [
        "print(x_train.shape, y_train.shape, np.min(y_train), np.max(y_train))\n",
        "print(x_train.dtype, np.min(x_train), np.max(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trPz49CobO5V"
      },
      "source": [
        "Ok, so a bunch of 32x32 images with three (RGB) channels. Targets are in [0, 9] (i.e. 10 classes). \n",
        "\n",
        "We don't like very much these large integer values, though. Let's rescale them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1ck9_bT3-n0"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "rescale = Rescaling(1./255)\n",
        "rescaled_image = rescale(x_train[0])\n",
        "print(np.min(rescaled_image), np.max(rescaled_image))\n",
        "print(\"Yay!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHchUNI0bMr-"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64MQ46dibrRx"
      },
      "source": [
        "plt.imshow(x_train[0])\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxKNPpLDb_Xu"
      },
      "source": [
        "A beautiful image. What do you see?\n",
        "\n",
        "Let's see if a neural network is better than you at this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJjVlBSEcKTW"
      },
      "source": [
        "## Convolutional Neural Network: the hammer for every nails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwFa_Kb47Lu9"
      },
      "source": [
        "Here comes the \"monster\".  \n",
        "I'm not providing you a good model, just a model.  \n",
        "The good model is for you to find!\n",
        "\n",
        "GPU strongly suggested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD-w-B5obt6S"
      },
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Modified from here:\n",
        "    https://keras.io/examples/vision/image_classification_from_scratch/#introduction\n",
        "    \"\"\"\n",
        "\n",
        "    rescaling = Rescaling(1./255)\n",
        "    inputs = K.Input(shape=input_shape)\n",
        "    x = rescaling(inputs)\n",
        "\n",
        "\n",
        "    x = K.layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = K.layers.BatchNormalization()(x)\n",
        "    x = K.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = K.layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = K.layers.BatchNormalization()(x)\n",
        "    x = K.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = K.layers.Conv2D(128, 3, padding=\"same\")(x)\n",
        "    x = K.layers.BatchNormalization()(x)\n",
        "    x = K.layers.Activation(\"relu\")(x)\n",
        "    x = K.layers.MaxPool2D(3)(x)\n",
        "\n",
        "    x = K.layers.Conv2D(256, 3, padding=\"same\")(x)\n",
        "    x = K.layers.BatchNormalization()(x)\n",
        "    x = K.layers.Activation(\"relu\")(x)\n",
        "    x = K.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "    # keep only batch size and num channels dimension\n",
        "    # pool over spatial dimensions\n",
        "    x = K.layers.GlobalAveragePooling2D()(x) \n",
        "    x = K.layers.Dropout(0.5)(x)\n",
        "    outputs = K.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return K.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqeMJ1hb6BUI"
      },
      "source": [
        "model = make_model(input_shape=(32, 32, 3), num_classes=10)\n",
        "K.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Aoytld_i7X"
      },
      "source": [
        "model.compile(optimizer=K.optimizers.Adam(1e-3), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH7sZ94j-Br6"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X78l-etbeM5Y"
      },
      "source": [
        "What about a [simpler neural network](https://keras.io/examples/vision/mnist_convnet/)? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCItCYC0_3UH"
      },
      "source": [
        "metrics = model.evaluate(x_test, y_test)\n",
        "print(metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNkD6JgA3kvu"
      },
      "source": [
        "**Exercise**: your turn! Design a convolutional neural network and try it out! \n",
        "\n",
        "You can work with MNIST which is a simpler dataset. Training should take less time. However, please consider that those images have only 1 channel (gray-scaled). Try it out :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKsNflsSdbB4"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHcaCnsSddtj"
      },
      "source": [
        "Gathering a dataset of images costs! If you need more images you can augment your dataset with transformations. In the end, a rotated cat is still a cat, isn't it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uStqRSydm85"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation, RandomTranslation\n",
        "\n",
        "rot = RandomRotation(factor=(-0.2, 0.2))\n",
        "tra = RandomTranslation(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2F95VCFz83P"
      },
      "source": [
        "# preprocess images before plotting\n",
        "# ensure batch size exist before preprocessing and do not before plot\n",
        "toplot = [rot(np.expand_dims(x_train[0], axis=0))[0] for _ in range(3)] + \\\n",
        " [tra(np.expand_dims(x_train[0], axis=0))[0] for _ in range(2)]\n",
        "toplot.append(x_train[0]) # append also real image for comparison\n",
        "\n",
        "toplot = iter(toplot) # convert to iterator to not deal with indices\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
        "for i in range(2):\n",
        "  for j in range(3):\n",
        "    ax[i, j].imshow(next(toplot))\n",
        "    ax[i, j].axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcCw7p0s3dCi"
      },
      "source": [
        "You can plug these layers into a Keras model as usual. If you do this way, the layer automatically apply data augmentation only **during training**. In fact, you don't want to augment your data during evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8Q8fPcy3gCT"
      },
      "source": [
        "**Exercise**: try to use data augmentation on your model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpDqhm_kxrEO"
      },
      "source": [
        "You can also try to use the [`ImageDataGenerator`](https://keras.io/api/preprocessing/image/#imagedatagenerator-class)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3QTE_Aedn1t"
      },
      "source": [
        "## Leverage pretrained networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8uSDB9zdtU5"
      },
      "source": [
        "If a network is trained on a large collection of images, it already contains valuable knowledge which can be reused \"for free\".  \n",
        "You can take an existing network and **finetuning** it on your data. This way, you also need less data! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqfOdibHfwl2"
      },
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "\n",
        "# RESCALING BY 255 IS INCLUDED IN EFFICIENT NET\n",
        "model = EfficientNetB0(weights=\"imagenet\", include_top=True) # (224, 224, 3)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "help(EfficientNetB0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0_bo5nvkND7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7X53G8ghsWs"
      },
      "source": [
        "# model.predict(x_train) # this raises an error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWxBWVyvh_wD"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "\n",
        "# resize with interpolation\n",
        "# better than padding\n",
        "res = Resizing(width=224, height=224) \n",
        "x_train_efficient = res(x_train[:2]) / 255\n",
        "print(x_train_efficient.shape)\n",
        "y_train_efficient = y_train[:2]\n",
        "plt.imshow(x_train_efficient[0])\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8up04wTkcc9"
      },
      "source": [
        "pred = model.predict(x_train_efficient)\n",
        "print(tf.argmax(pred, axis=1), pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j7bib8gkwWD"
      },
      "source": [
        "We are working with different classes with respect to the ones the model have been trained on!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGzzh6w2o3_J"
      },
      "source": [
        "def get_model2():\n",
        "  eff = EfficientNetB0(weights=\"imagenet\", include_top=False)\n",
        "  eff.trainable = False\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(K.layers.Input(shape=(32, 32, 3)))\n",
        "  model.add(Resizing(width=224, height=224))\n",
        "  model.add(eff)\n",
        "  model.add(K.layers.Flatten())\n",
        "  model.add(K.layers.Dense(10, activation=\"softmax\"))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMb1ZsEBvLvs"
      },
      "source": [
        "model = get_model2()\n",
        "# you can use larger learning rate\n",
        "model.compile(optimizer=K.optimizers.Adam(1e-2), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj51a4eQlVis"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=2, batch_size=256, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYesIhABmbe1"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxbAO2KsrsQL"
      },
      "source": [
        "You can also unfreeze some EfficientNet layer and proceed to finetune them with a slower learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJzdxVAQrwiq"
      },
      "source": [
        "def unfreeze_model(model):\n",
        "  for layer in model.layers[-20:]:\n",
        "    if not isinstance(layer, K.layers.BatchNormalization):\n",
        "      layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teYKQROFuAXP"
      },
      "source": [
        "## Inspect convolutional feature maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYjW_qEXvVAF"
      },
      "source": [
        "model = K.applications.ResNet50V2(weights=\"imagenet\", include_top=False)\n",
        "model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8VHM2Mlwc62"
      },
      "source": [
        "img_width = 180\n",
        "img_height = 180\n",
        "layer_name = \"conv3_block4_out\"\n",
        "\n",
        "layer = model.get_layer(name=\"conv3_block4_out\")\n",
        "feature_extractor = K.Model(inputs=model.inputs, outputs=layer.output)\n",
        "\n",
        "def compute_loss(input_image, filter_index):\n",
        "    activation = feature_extractor(input_image)\n",
        "    filter_activation = activation[:, :, :, filter_index]\n",
        "    return tf.reduce_mean(filter_activation)\n",
        "\n",
        "@tf.function\n",
        "def gradient_ascent_step(img, filter_index, learning_rate):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img)\n",
        "        loss = compute_loss(img, filter_index)\n",
        "    grads = tape.gradient(loss, img)\n",
        "    grads = tf.math.l2_normalize(grads)\n",
        "    img += learning_rate * grads\n",
        "    return loss, img\n",
        "\n",
        "def initialize_image():\n",
        "    img = tf.random.uniform((1, img_width, img_height, 3))\n",
        "    # ResNet50V2 expects inputs in the range [-1, +1].\n",
        "    # Here we scale our random inputs to [-0.125, +0.125]\n",
        "    return (img - 0.5) * 0.25\n",
        "\n",
        "\n",
        "def visualize_filter(filter_index):\n",
        "    # We run gradient ascent for 20 steps\n",
        "    iterations = 30\n",
        "    learning_rate = 10\n",
        "    img = initialize_image()\n",
        "    for iteration in range(iterations):\n",
        "        loss, img = gradient_ascent_step(img, filter_index, learning_rate)\n",
        "\n",
        "    # Decode the resulting input image\n",
        "    img = deprocess_image(img[0].numpy())\n",
        "    return loss, img\n",
        "\n",
        "\n",
        "def deprocess_image(img):\n",
        "    # Normalize array: center on 0., ensure variance is 0.15\n",
        "    img -= img.mean()\n",
        "    img /= img.std() + 1e-5\n",
        "    img *= 0.15\n",
        "\n",
        "    # Clip to [0, 1]\n",
        "    img += 0.5\n",
        "    img = np.clip(img, 0, 1)\n",
        "\n",
        "    # Convert to RGB array\n",
        "    img *= 255\n",
        "    img = np.clip(img, 0, 255).astype(\"uint8\")\n",
        "    return img\n",
        "\n",
        "\n",
        "loss, img = visualize_filter(0)\n",
        "print(loss, img.shape)\n",
        "K.preprocessing.image.save_img(\"0.png\", img)\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KC_7_cnucmV"
      },
      "source": [
        "You can try different blocks and filters to see what they recognize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0SMNvIePVT"
      },
      "source": [
        "## Not only image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm2myYD5eSrJ"
      },
      "source": [
        "There are other, quite important, tasks. Object detection (the nice squares around faces) and image segmentation (each pixel belongs to a specific class),for example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9KLbdePtWMp"
      },
      "source": [
        "You can check out Keras examples: [object detection](https://keras.io/examples/vision/retinanet/#downloading-the-coco2017-dataset), [image segmentation](https://keras.io/examples/vision/oxford_pets_image_segmentation/).\n",
        "\n",
        "If you want to try some of them out, I'd recommend the latter since it has a simpler preparation."
      ]
    }
  ]
}